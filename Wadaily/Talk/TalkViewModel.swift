//
//  TalkViewModel.swift
//  Wadaily
//
//  Created by æµ¦å±±ç§€æ–— on 2025/12/03.
//

import Combine
import AgoraRtcKit

enum TalkViewState {
    case disconnected      // æœªæ¥ç¶š
    case connecting        // æ¥ç¶šä¸­
    case channelJoined     // ãƒãƒ£ãƒ³ãƒãƒ« joined
    case talking           // é€šè©±ä¸­
    case callEnded         // é€šè©±çµ‚äº†
}

class TalkViewModel: ObservableObject {
    @Published var state: TalkViewState = .disconnected
    @Published var isMuted: Bool = false
    @Published var currentConversation: [ConversationMessage] = []
    @Published var suggestedTopics: [String] = []
    
    // éŸ³å£°è¨­å®š
    private let SAMPLING_RATE = 24000 // ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆ (Hz)
    private let MESSAGE_THRESHOLD = 10 // è©±é¡Œææ¡ˆã‚’è¡Œã†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°ã®é–¾å€¤
    
    // STT APIãƒªã‚¯ã‚¨ã‚¹ãƒˆç”¨ãƒãƒƒãƒ•ã‚¡è¨­å®š
    private let STT_BUFFER_DURATION_MS = 3000 // STT APIã«é€ä¿¡ã™ã‚‹éŸ³å£°ã®é•·ã• (3ç§’)
    private var myAudioBuffer = Data() // è‡ªåˆ†ã®éŸ³å£°ãƒãƒƒãƒ•ã‚¡
    private var partnerAudioBuffer = Data() // ç›¸æ‰‹ã®éŸ³å£°ãƒãƒƒãƒ•ã‚¡
    private let bufferQueue = DispatchQueue(label: "com.wadaily.audiobuffer", qos: .userInteractive)
    
    private let me: Caller
    private let partner: Caller
    
    private var agoraManager: AgoraManager?
    private var coordinator: AgoraEngineCoordinator?
    private let partnerSpeechToTextService: SpeechToTextServiceProtocol // ç›¸æ‰‹ç”¨ã®Speech-to-Textã‚µãƒ¼ãƒ“ã‚¹
    private let mySpeechToTextService: SpeechToTextServiceProtocol      // è‡ªåˆ†ç”¨ã®Speech-to-Textã‚µãƒ¼ãƒ“ã‚¹
    private let topicWebSocketService: TopicWebSocketServiceProtocol    // è©±é¡Œææ¡ˆç”¨ã®WebSocketã‚µãƒ¼ãƒ“ã‚¹
    private var lastPushedMessageCount = 0
    
    // WebSocketæ¥ç¶šçŠ¶æ…‹ãƒ•ãƒ©ã‚°
    private var isMySttConnected = false
    private var isPartnerSttConnected = false
    private var isTopicWebSocketConnected = false

    init(
        me: Caller,
        partner: Caller,
        partnerSpeechToTextService: SpeechToTextServiceProtocol = SpeechToTextService(),
        mySpeechToTextService: SpeechToTextServiceProtocol = SpeechToTextService(),
        topicWebSocketService: TopicWebSocketServiceProtocol = TopicWebSocketService()
    ) {
        self.me = me
        self.partner = partner
        self.partnerSpeechToTextService = partnerSpeechToTextService
        self.mySpeechToTextService = mySpeechToTextService
        self.topicWebSocketService = topicWebSocketService
        coordinator = AgoraEngineCoordinator(delegate: self)
        if let coordinator = coordinator {
            agoraManager = AgoraManager(delegate: coordinator, audioFrameDelegate: coordinator)
        }
        
        // ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’WebSocketã‚µãƒ¼ãƒ“ã‚¹ã«è¨­å®š
        let meProfile = UserProfile(userId: me.userId, snsData: SNSData.dummy(for: me.userId))
        let partnerProfile = UserProfile(userId: partner.userId, snsData: SNSData.dummy(for: partner.userId))
        topicWebSocketService.setUserProfiles(me: meProfile, partner: partnerProfile)
    }
    
    private func setupWebSoketSessions() {
        print("ğŸ”Œ [TalkViewModel] Setting up WebSocket sessions...")
        Task {
            do {
                // è‡ªåˆ†ã®éŸ³å£°ç”¨ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹
                print("ğŸ¤ [TalkViewModel] Starting My Speech-to-Text session...")
                try await mySpeechToTextService.startSession(
                    sampleRate: SAMPLING_RATE,
                    channels: 1,
                    callback: onReceivedMyText
                )
                isMySttConnected = true
                print("âœ… [TalkViewModel] My Speech-to-Text session started")

                // ç›¸æ‰‹ã®éŸ³å£°ç”¨ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹
                print("ğŸ¤ [TalkViewModel] Starting Partner Speech-to-Text session...")
                try await partnerSpeechToTextService.startSession(
                    sampleRate: SAMPLING_RATE,
                    channels: 1,
                    callback: onReceivedPartnerText
                )
                isPartnerSttConnected = true
                print("âœ… [TalkViewModel] Partner Speech-to-Text session started")
                
                // è©±é¡Œææ¡ˆAPIç”¨ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹
                print("ğŸ”Œ [TalkViewModel] Starting Topic WebSocket session...")
                try await topicWebSocketService.startSession(callback: onReceivedTopics)
                isTopicWebSocketConnected = true
                print("âœ… [TalkViewModel] WebSocket session started for topic suggestions")
            } catch {
                print("âŒ [TalkViewModel] Failed to start sessions: \(error.localizedDescription)")
            }
        }
    }
    
    func joinChannel() {
        state = .connecting
        Task {
            do {
                try await agoraManager?.joinChannel(channelName: partner.buildChannelName(with: me), uid: me.talkId)
            } catch {
                state = .disconnected
                print("Failed to join channel: \(error)")
            }
        }
    }

    func leaveChannel() {
        // ã¾ãšAgoraãƒãƒ£ãƒ³ãƒãƒ«ã‹ã‚‰é›¢è„±
        agoraManager?.leaveChannel()
        
        // æ¥ç¶šãƒ•ãƒ©ã‚°ã‚’ãƒªã‚»ãƒƒãƒˆ
        isMySttConnected = false
        isPartnerSttConnected = false
        
        // ãƒãƒƒãƒ•ã‚¡ã‚’ã‚¯ãƒªã‚¢
        bufferQueue.async { [weak self] in
            self?.myAudioBuffer.removeAll()
            self?.partnerAudioBuffer.removeAll()
        }
        
        // ãã®å¾Œã€WebSocketã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        Task {
            await partnerSpeechToTextService.endSession()
            await mySpeechToTextService.endSession()
            await topicWebSocketService.endSession()
        }
    }
    
    func toggleMute() {
        isMuted.toggle()
        if isMuted {
            agoraManager?.onMute()
        } else {
            agoraManager?.offMute()
        }
    }
    
    /// ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€5ä»¶æºœã¾ã£ãŸã‚‰ã‚µãƒ¼ãƒãƒ¼ã«ãƒ—ãƒƒã‚·ãƒ¥
    private func checkAndPushMessages() {
        guard currentConversation.count >= MESSAGE_THRESHOLD else { return }
        
        // WebSocketæ¥ç¶šãŒå®Œäº†ã—ã¦ã„ãªã„å ´åˆã¯é€ä¿¡ã—ãªã„
        guard isTopicWebSocketConnected else {
            print("â¸ï¸ Topic WebSocket not connected yet, skipping push")
            return
        }
        
        let toPushMessages = currentConversation
        currentConversation = []
        
        // éåŒæœŸã§ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ãƒ—ãƒƒã‚·ãƒ¥ï¼ˆå¾…ãŸãªã„ï¼‰
        Task {
            do {
                try await topicWebSocketService.pushMessages(toPushMessages)
                print("ğŸ’¬ Pushed \(toPushMessages.count) messages to server")
            } catch {
                print("âŒ Failed to push messages: \(error)")
            }
        }
    }
}

// MARK: - Agora Delegates
extension TalkViewModel: AgoraEngineCoordinatorDelegate {
    //MARK: - Event from me
    func didJoined(uid: UInt) {
        guard (uid == me.talkId) else { return }
        state = .channelJoined
        print("I joined with uid: \(uid)")
    }
    
    func didLeaveChannel() {
        state = .callEnded
        print("Left channel")
    }
    
    func didReceiveMyAudioFrame(_ frame: AgoraAudioFrame) {
        // è‡ªåˆ†ã®PCMãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†
        guard let buffer = frame.buffer else { return }
        
        // PCMãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º (16-bit samples)
        let byteCount = Int(frame.samplesPerChannel * frame.channels * 2)
        let pcmData = Data(bytes: buffer, count: byteCount)
        
        // ãƒãƒƒãƒ•ã‚¡ã«è¿½åŠ ã—ã¦ã€ä¸€å®šã‚µã‚¤ã‚ºã«ãªã£ãŸã‚‰STT APIã«é€ä¿¡
        bufferQueue.async { [weak self] in
            guard let self = self else { return }
            self.myAudioBuffer.append(pcmData)
            
            // ç›®æ¨™ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚º (3ç§’åˆ† = 24000 Hz * 3ç§’ * 2 bytes = 144,000 bytes)
            let targetBufferSize = (self.SAMPLING_RATE * self.STT_BUFFER_DURATION_MS * 2) / 1000
            
            if self.myAudioBuffer.count >= targetBufferSize {
                let dataToSend = self.myAudioBuffer
                self.myAudioBuffer.removeAll(keepingCapacity: true)
                
                // WebSocketæ¥ç¶šãŒç¢ºç«‹ã•ã‚Œã¦ã„ã‚‹å ´åˆã®ã¿é€ä¿¡
                if self.isMySttConnected {
                    // STT APIã«é€ä¿¡ï¼ˆéåŒæœŸãƒ»å¾…ãŸãªã„ï¼‰
                    Task.detached {
                        do {
                            try await self.mySpeechToTextService.sendAudioData(dataToSend)
                        } catch {
                            print("âŒ Failed to send my audio data: \(error)")
                        }
                    }
                }
            }
        }
    }
    
    func didOccurError() {
        state = .callEnded
        print("occur error")
    }
    
    //MARK: - Event from partner
    func didPartnerJoined(uid: UInt) {
        state = .talking
        print("Partner joined with uid: \(uid)")
        
        // WebSocketã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’éåŒæœŸã§é–‹å§‹ï¼ˆå¾…ãŸãªã„ï¼‰
        // éŸ³å£°å‡¦ç†ã‚’ãƒ–ãƒ­ãƒƒã‚¯ã—ãªã„ãŸã‚ã€ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§å®Ÿè¡Œ
        setupWebSoketSessions()
    }
    
    func didPartnerLeave(uid: UInt) {
        state = .callEnded
        // ã¾ãšAgoraãƒãƒ£ãƒ³ãƒãƒ«ã‹ã‚‰é›¢è„±
        agoraManager?.leaveChannel()
        
        // æ¥ç¶šãƒ•ãƒ©ã‚°ã‚’ãƒªã‚»ãƒƒãƒˆ
        isMySttConnected = false
        isPartnerSttConnected = false
        isTopicWebSocketConnected = false
        
        // ãƒãƒƒãƒ•ã‚¡ã‚’ã‚¯ãƒªã‚¢
        bufferQueue.async { [weak self] in
            self?.myAudioBuffer.removeAll()
            self?.partnerAudioBuffer.removeAll()
        }
        
        // ãã®å¾Œã€WebSocketã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        Task {
            await partnerSpeechToTextService.endSession()
            await mySpeechToTextService.endSession()
            await topicWebSocketService.endSession()
        }
        print("Partner lefted with uid: \(uid)")
    }
    
    func didReceivePartnerAudioFrame(_ frame: AgoraAudioFrame) {
        // ç›¸æ‰‹ã®PCMãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†
        guard let buffer = frame.buffer else { return }
        
        // PCMãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º (16-bit samples)
        let byteCount = Int(frame.samplesPerChannel * frame.channels * 2)
        let pcmData = Data(bytes: buffer, count: byteCount)
        
        // ãƒãƒƒãƒ•ã‚¡ã«è¿½åŠ ã—ã¦ã€ä¸€å®šã‚µã‚¤ã‚ºã«ãªã£ãŸã‚‰STT APIã«é€ä¿¡
        bufferQueue.async { [weak self] in
            guard let self = self else { return }
            self.partnerAudioBuffer.append(pcmData)
            
            // ç›®æ¨™ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚º (3ç§’åˆ† = 24000 Hz * 3ç§’ * 2 bytes = 144,000 bytes)
            let targetBufferSize = (self.SAMPLING_RATE * self.STT_BUFFER_DURATION_MS * 2) / 1000
            
            if self.partnerAudioBuffer.count >= targetBufferSize {
                let dataToSend = self.partnerAudioBuffer
                self.partnerAudioBuffer.removeAll(keepingCapacity: true)
                
                // WebSocketæ¥ç¶šãŒç¢ºç«‹ã•ã‚Œã¦ã„ã‚‹å ´åˆã®ã¿é€ä¿¡
                if self.isPartnerSttConnected {
                    // STT APIã«é€ä¿¡ï¼ˆéåŒæœŸãƒ»å¾…ãŸãªã„ï¼‰
                    Task.detached {
                        do {
                            try await self.partnerSpeechToTextService.sendAudioData(dataToSend)
                        } catch {
                            print("âŒ Failed to send partner audio data: \(error)")
                        }
                    }
                }
            }
        }
    }
}

// MARK: - Wadaily Callbacks
extension TalkViewModel {
    /// è‡ªåˆ†ã®éŸ³å£°ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆå¤‰æ›çµæœã‚’å—ã‘å–ã‚‹ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°
    private func onReceivedMyText(_ result: Result<String, Error>) {
        let textId = UUID().uuidString.prefix(8)
        print("ğŸ“¥ [TalkViewModel-\(textId)] Callback invoked for MY text")
        
        switch result {
        case .success(let text):
            print("ğŸ“ [TalkViewModel-\(textId)] My recognized text: \(text)")
            Task { @MainActor in
                let message = ConversationMessage(
                    userId: me.talkId,
                    text: text,
                    timestamp: Date()
                )
                currentConversation.append(message)
                checkAndPushMessages()
            }
        case .failure(let error):
            print("âŒ [TalkViewModel-\(textId)] My speech to text conversion failed: \(error.localizedDescription)")
        }
    }
    
    /// ç›¸æ‰‹ã®éŸ³å£°ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆå¤‰æ›çµæœã‚’å—ã‘å–ã‚‹ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°
    private func onReceivedPartnerText(_ result: Result<String, Error>) {
        let textId = UUID().uuidString.prefix(8)
        print("ğŸ“¥ [TalkViewModel-\(textId)] Callback invoked for PARTNER text")
        
        switch result {
        case .success(let text):
            print("ğŸ“ [TalkViewModel-\(textId)] Partner recognized text: \(text)")
            Task { @MainActor in
                let message = ConversationMessage(
                    userId: partner.talkId,
                    text: text,
                    timestamp: Date()
                )
                currentConversation.append(message)
                checkAndPushMessages()
            }
        case .failure(let error):
            print("âŒ [TalkViewModel-\(textId)] Partner speech to text conversion failed: \(error.localizedDescription)")
        }
    }
    
    /// WebSocketã‹ã‚‰è©±é¡Œææ¡ˆã‚’å—ã‘å–ã‚‹ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°
    private func onReceivedTopics(_ topics: [String]) {
        Task { @MainActor in
            print("==================SUCCESS=======================")
            print("ğŸ’¡ Received topics: \(topics)")
            suggestedTopics = topics
        }
    }
}           
